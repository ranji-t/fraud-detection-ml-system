{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "from typing import TypedDict\n",
    "\n",
    "# Third Party imports\n",
    "import jax\n",
    "import optax\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import jax.numpy as jnp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data() -> tuple[jax.Array, jax.Array, jax.Array, jax.Array]:\n",
    "    # Read data\n",
    "    df = pl.read_csv(\n",
    "        r\"D:\\Codebase\\fraud-detection\\data\\input\\creditcard.csv\",\n",
    "        ignore_errors=False,\n",
    "        infer_schema_length=1000_000,\n",
    "    )\n",
    "\n",
    "    # Split data into X and y\n",
    "    x = df.select(pl.exclude(\"Class\")).to_pandas()\n",
    "    y = df.select(\"Class\").to_series().to_pandas()\n",
    "\n",
    "    # Set type of the splits\n",
    "    X_train: pd.DataFrame\n",
    "    y_train: pd.Series\n",
    "    X_test: pd.DataFrame\n",
    "    y_test: pd.Series\n",
    "\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # The class distribution in training set\n",
    "    display(y_train.value_counts(normalize=False))\n",
    "    display(y_train.value_counts(normalize=True).round(4) * 100)\n",
    "\n",
    "    # # The Target Mapping\n",
    "    # target_mapping = {0: \"Legitimate\", 1: \"Fraudulent\"}\n",
    "\n",
    "    # Convert DataFrame to Jax arrays\n",
    "    X_train_jnp = jnp.array(X_train.values)\n",
    "    y_train_jnp = jnp.array(y_train.values).reshape(-1, 1)\n",
    "    X_test_jnp = jnp.array(X_test.values)\n",
    "    y_test_jnp = jnp.array(y_test.values).reshape(-1, 1)\n",
    "\n",
    "    return X_train_jnp, y_train_jnp, X_test_jnp, y_test_jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaxStdScaler:\n",
    "    def __init__(self) -> None:\n",
    "        self.mean: None | jax.Array = None\n",
    "        self.std: None | jax.Array = None\n",
    "\n",
    "    def fit(self, X: jax.Array) -> None:\n",
    "        self.mean = jnp.mean(X, axis=0)\n",
    "        self.std = jnp.std(X, axis=0)\n",
    "\n",
    "    def transform(self, X: jax.Array) -> jax.Array:\n",
    "        if self.mean is None or self.std is None:\n",
    "            raise ValueError(\"The JaxStdScaler has not been fitted yet.\")\n",
    "        return self._transform(X=X, mean=self.mean, std=self.std)\n",
    "\n",
    "    def fit_transform(self, X: jax.Array) -> jax.Array:\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "    @staticmethod\n",
    "    @jax.jit\n",
    "    def _transform(X: jax.Array, mean: jax.Array, std: jax.Array) -> jax.Array:\n",
    "        return (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParams(TypedDict, total=True):\n",
    "    weights: jnp.ndarray\n",
    "    bias: jnp.ndarray\n",
    "\n",
    "\n",
    "class DataFeatures(TypedDict, total=True):\n",
    "    n_features: int\n",
    "    n_targets: int\n",
    "\n",
    "\n",
    "def init_model_params(data_features: DataFeatures, seed: int = 1729) -> ModelParams:\n",
    "    \"\"\"Initialize model parameters.\"\"\"\n",
    "    # Set Keys\n",
    "    key = jax.random.key(seed=seed)\n",
    "\n",
    "    # Split keys\n",
    "    w_key, b_key = jax.random.split(key=key, num=2)\n",
    "    # init weights\n",
    "    weights = jax.random.normal(\n",
    "        key=w_key, shape=(data_features[\"n_features\"], data_features[\"n_targets\"])\n",
    "    )\n",
    "    bias = jax.random.normal(key=b_key, shape=(data_features[\"n_targets\"],))\n",
    "\n",
    "    # Return data\n",
    "    return {\"weights\": weights, \"bias\": bias}\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def predict_logits(params: ModelParams, X: jax.Array) -> jax.Array:\n",
    "    return jnp.matmul(X, params[\"weights\"]) + params[\"bias\"]\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def predict_proba(params: ModelParams, X: jax.Array) -> jax.Array:\n",
    "    # Get Log odds\n",
    "    z = predict_logits(params=params, X=X)\n",
    "    # Get Probabalities from Log odds\n",
    "    return jax.nn.sigmoid(z)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def weighted_sigmoid_bce(\n",
    "    logits: jax.Array, labels: jax.Array, pos_weight: float, neg_weight: float\n",
    ") -> jax.Array:\n",
    "    # Base loss\n",
    "    loss = optax.sigmoid_binary_cross_entropy(logits, labels)\n",
    "\n",
    "    # weights\n",
    "    Wy = (pos_weight * labels) + (neg_weight * (1 - labels))\n",
    "\n",
    "    # Return Weighted BCE\n",
    "    return (loss * Wy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def forward_pass(\n",
    "    params: ModelParams,\n",
    "    X: jax.Array,\n",
    "    y: jax.Array,\n",
    "    pos_weight: float,\n",
    "    neg_weight: float,\n",
    "):\n",
    "    # Get prediction in Logits\n",
    "    logits = predict_logits(params=params, X=X)\n",
    "    # Compute loss\n",
    "    loss = weighted_sigmoid_bce(\n",
    "        logits=logits, labels=y, pos_weight=pos_weight, neg_weight=neg_weight\n",
    "    )\n",
    "    # Return Loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "# The Gradiet function\n",
    "grad_func = jax.jit(jax.value_and_grad(forward_pass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Process data\n",
    "X_train_jnp, y_train_jnp, X_test_jnp, y_test_jnp = get_data()\n",
    "\n",
    "# Scale the data\n",
    "feature_scaler = JaxStdScaler()\n",
    "X_train_sc = feature_scaler.fit_transform(X_train_jnp)\n",
    "X_test_sc = feature_scaler.transform(X_test_jnp)\n",
    "\n",
    "# Define Data Featues\n",
    "data_features: DataFeatures = {\n",
    "    \"n_features\": X_train_sc.shape[1],\n",
    "    \"n_targets\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultRecord(TypedDict, total=True):\n",
    "    epoch: int\n",
    "    loss: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init parameters\n",
    "params = init_model_params(data_features=data_features)\n",
    "\n",
    "# Weight for imblalnced classes\n",
    "pos_weight: float = float(99.83 / 0.17)\n",
    "neg_weight: float = float(1)\n",
    "\n",
    "# Get Logit (Log Odds)\n",
    "logits_train = predict_logits(params, X_train_sc)\n",
    "\n",
    "# Start learning rate & Schedulers\n",
    "start_lr = 1e-1\n",
    "schedule = optax.schedules.piecewise_constant_schedule(\n",
    "    start_lr, {10: 1e-2, 30: 1e-3, 40: 1e-4}\n",
    ")\n",
    "\n",
    "# Set Optimizer\n",
    "optimizer = optax.adam(learning_rate=schedule)\n",
    "# initialize Parameters\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "# number of epochs\n",
    "epochs: int = 50\n",
    "loss: float | None = None\n",
    "history: list[ResultRecord] = list()\n",
    "\n",
    "# Iterate through Epochs\n",
    "for epoch in tqdm(\n",
    "    range(epochs),\n",
    "    desc=f\"Last Epoch Loss: {loss}\" if (loss is not None) else \"Training Epoch Started\",\n",
    "):\n",
    "    # Compute Loss and Grads\n",
    "    loss, grads = grad_func(\n",
    "        params,\n",
    "        X=X_train_sc,\n",
    "        y=y_train_jnp,\n",
    "        pos_weight=pos_weight,\n",
    "        neg_weight=neg_weight,\n",
    "    )\n",
    "\n",
    "    # Update params\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "\n",
    "    # Loss logged\n",
    "    history.append({\"epoch\": epoch, \"loss\": float(loss)})\n",
    "\n",
    "# Create figure for loss plotting\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add loss trace\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[h[\"epoch\"] for h in history],\n",
    "        y=[h[\"loss\"] for h in history],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Training Loss\",\n",
    "        hovertemplate=\"Epoch: %{x}<br>Loss: %{y:.4f}<extra></extra>\",\n",
    "        line=dict(width=2),\n",
    "        marker=dict(size=6),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout with better formatting\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"<b>Loss Tracking Through Epochs</b>\", x=0.5, font=dict(size=20)),\n",
    "    xaxis_title=\"<b>Epoch</b>\",\n",
    "    yaxis_title=\"<b>Loss</b>\",\n",
    "    hovermode=\"x unified\",\n",
    "    template=\"plotly_dark\",\n",
    "    width=1400,\n",
    "    height=500,\n",
    "    showlegend=True,\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction\n",
    "y_pred_train = predict_proba(params=params, X=X_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preciion Recall Curve\n",
    "precision, recall, threshold = precision_recall_curve(\n",
    "    y_train_jnp.reshape(-1), y_pred_train.reshape(-1)\n",
    ")\n",
    "# Compute F1 Score\n",
    "beta = 15\n",
    "f1 = (1 + beta**2) * precision * recall / ((beta**2 * precision) + recall)\n",
    "\n",
    "prft = (\n",
    "    pd.DataFrame(\n",
    "        dict(\n",
    "            precision=precision[:-1],\n",
    "            recall=recall[:-1],\n",
    "            f1=f1[:-1],\n",
    "            threshold=threshold,\n",
    "        )\n",
    "    )\n",
    "    .sort_values([\"recall\", \"precision\"], ascending=[True, False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Print Precision Recall Curve\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=prft[\"recall\"][:-1],\n",
    "        y=prft[\"precision\"][:-1],\n",
    "        name=\"<b>Precision Recall Curve</b>\",\n",
    "        customdata=prft[[\"f1\", \"threshold\"]].values,\n",
    "        hovertemplate=(\n",
    "            \"Precision: %{y:.2%}<br>\"\n",
    "            \"Recall: %{x:.2%}<br>\"\n",
    "            \"F1: %{customdata[0]:.2%}<br>\"\n",
    "            \"Threshold: %{customdata[1]:%}\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Precision-Recall-Curve\", x=0.5, font=dict(size=25)),\n",
    "    xaxis_title=\"<b>Recall</b>\",\n",
    "    yaxis_title=\"<b>Precision</b>\",\n",
    "    template=\"plotly_dark\",\n",
    ")\n",
    "\n",
    "# Plot the Maximum\n",
    "max_f1_idx = prft[\"f1\"].argmax()\n",
    "max_f1_point = prft.iloc[max_f1_idx]\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[max_f1_point[\"recall\"]],\n",
    "        y=[max_f1_point[\"precision\"]],\n",
    "        mode=\"markers\",\n",
    "        name=\"<b>Maximum F1</b>\",\n",
    "        marker=dict(size=10, symbol=\"star\", color=\"red\"),\n",
    "        hovertemplate=(\n",
    "            \"Precision: %{y:.2%}<br>\"\n",
    "            \"Recall: %{x:.2%}<br>\"\n",
    "            f\"F1: {max_f1_point['f1']:.2%}<br>\"\n",
    "            f\"Threshold: {max_f1_point['threshold']:%}\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ROC curve values\n",
    "fpr, tpr, thresholds = roc_curve(y_train_jnp.reshape(-1), y_pred_train.reshape(-1))\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "roc_df = pd.DataFrame({\"fpr\": fpr, \"tpr\": tpr, \"threshold\": thresholds})\n",
    "\n",
    "# Create ROC curve plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add ROC curve trace\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=roc_df[\"fpr\"],\n",
    "        y=roc_df[\"tpr\"],\n",
    "        name=\"<b>ROC Curve</b>\",\n",
    "        customdata=roc_df[\"threshold\"],\n",
    "        hovertemplate=(\n",
    "            \"True Positive Rate: %{y:.2%}<br>\"\n",
    "            \"False Positive Rate: %{x:.2%}<br>\"\n",
    "            \"Threshold: %{customdata}\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add diagonal reference line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        line=dict(dash=\"dash\", color=\"gray\"),\n",
    "        name=\"<b>Random Classifier</b>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Receiver Operating Characteristic (ROC) Curve\", x=0.5, font=dict(size=25)\n",
    "    ),\n",
    "    xaxis_title=\"<b>False Positive Rate</b>\",\n",
    "    yaxis_title=\"<b>True Positive Rate</b>\",\n",
    "    template=\"plotly_dark\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
