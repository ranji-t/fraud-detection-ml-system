{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# **Fraud Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "from typing import Callable\n",
    "from functools import partial\n",
    "\n",
    "# Third Party Imports\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_predict,\n",
    "    cross_val_score,\n",
    "    RepeatedStratifiedKFold,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    log_loss,\n",
    "    brier_score_loss,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from optuna.importance import get_param_importances\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## *Read data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pl.read_csv(\n",
    "    r\"D:\\Codebase\\fraud-detection\\data\\input\\creditcard.csv\",\n",
    "    ignore_errors=False,\n",
    "    infer_schema_length=1000_000,\n",
    ")\n",
    "\n",
    "# Display data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## *Data Exploration*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Figure Object\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Trace to heatmap\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x=df.to_pandas().corr(method=\"pearson\").index,\n",
    "        y=df.to_pandas().corr(method=\"pearson\").columns,\n",
    "        z=df.to_pandas().corr(method=\"pearson\").values * 100,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Layout settings\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"<b>Correlation Heatmap</b>\", x=0.5, font=dict(size=24)),\n",
    "    xaxis_nticks=36,\n",
    "    yaxis_nticks=36,\n",
    "    height=800,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Subplot lay out\n",
    "columns = df.columns\n",
    "fig = make_subplots(\n",
    "    rows=len(columns),\n",
    "    cols=1,\n",
    "    subplot_titles=[f\"<B>{col} Distribution</B>\" for col in columns],\n",
    ")\n",
    "\n",
    "# Loop through columns and add histogram and box plot for each\n",
    "for i, col in enumerate(columns, start=1):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=df[col].to_pandas(),\n",
    "            name=f\"{col} Histogram\",\n",
    "            nbinsx=100,\n",
    "            # xaxis=\"Distribution\",\n",
    "            # yaxis=\"Count\",\n",
    "        ),\n",
    "        row=i,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "# Set Layout\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"<b>Feature Distributions</b>\", x=0.5, font=dict(size=24)),\n",
    "    height=300 * len(columns),\n",
    "    width=800,\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "# Show\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# **Data Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## *Data Split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "x = df.select(pl.exclude(\"Class\")).to_pandas()\n",
    "y = df.select(\"Class\").to_series().to_pandas()\n",
    "\n",
    "# Set type of the splits\n",
    "X_train: pd.DataFrame\n",
    "y_train: pd.Series\n",
    "X_test: pd.DataFrame\n",
    "y_test: pd.Series\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class distribution in training set\n",
    "display(y_train.value_counts(normalize=False))\n",
    "display(y_train.value_counts(normalize=True).round(4) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# **Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Objective Function type\n",
    "ObjectiveFunction = Callable[[optuna.trial.Trial], float]\n",
    "FullObjectiveFunction = Callable[[optuna.trial.Trial, pd.DataFrame, pd.Series], float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_classification_report(\n",
    "    model,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    ") -> None:\n",
    "    # Set up Cross Validation Policy\n",
    "    cv_policy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Get Predictions using Cross Validation\n",
    "    y_train_pred = cross_val_predict(\n",
    "        model, X_train, y_train, cv=cv_policy, method=\"predict\", verbose=0\n",
    "    )\n",
    "    y_train_proba = cross_val_predict(\n",
    "        model, X_train, y_train, cv=cv_policy, method=\"predict_proba\", verbose=0\n",
    "    )\n",
    "\n",
    "    # Show Basic Metrics\n",
    "    print(f\"Accuracy         : {accuracy_score(y_train, y_train_pred):.2%}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_train, y_train_pred):.2%}\")\n",
    "    print(f\"F1 Score         : {f1_score(y_train, y_train_pred):.2%}\")\n",
    "    print(f\"Precision        : {precision_score(y_train, y_train_pred):.2%}\")\n",
    "    print(f\"Recall           : {recall_score(y_train, y_train_pred):.2%}\")\n",
    "    print(f\"AP Score    : {average_precision_score(y_train, y_train_proba[:, 1]):.2%}\")\n",
    "    print(f\"Log Loss    : {log_loss(y_train, y_train_proba):.4f}\")\n",
    "    print(f\"Brier Score : {brier_score_loss(y_train, y_train_proba[:, 1]):.4f}\")\n",
    "\n",
    "    # Show Confusion Matrix\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            confusion_matrix(y_train, y_train_pred),\n",
    "            columns=[\"Pred-Normal-Transaction\", \"Pred-Fraud-Transaction\"],\n",
    "            index=[\"Actual-Normal-Transaction\", \"Actual-Fraud-Transaction\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Show Classification Report\n",
    "    print(classification_report(y_train, y_train_pred, zero_division=np.nan))\n",
    "\n",
    "    # Return nothing\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_dt_objective(\n",
    "    trial: optuna.trial.Trial, X_train: pd.DataFrame, y_train: pd.Series\n",
    ") -> float:\n",
    "    # Parameter Dict for this trial\n",
    "    params_dict = dict(\n",
    "        ## Tree Policy\n",
    "        criterion=trial.suggest_categorical(\n",
    "            \"criterion\", [\"gini\", \"entropy\", \"log_loss\"]\n",
    "        ),\n",
    "        splitter=trial.suggest_categorical(\"splitter\", [\"random\", \"best\"]),\n",
    "        class_weight=trial.suggest_categorical(\"class_weight\", [\"balanced\", None]),\n",
    "        ## pre-pruning\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 1, 100),\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        # post-pruning\n",
    "        ccp_alpha=trial.suggest_float(\"ccp_alpha\", 0.0, 4, step=0.0001),\n",
    "    )\n",
    "\n",
    "    # Set the paramters in the decision tree\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt = dt.set_params(**params_dict)\n",
    "\n",
    "    # Set Cross Validation Policy & Cross Val Score\n",
    "    cv_policy = RepeatedStratifiedKFold(n_splits=4, n_repeats=2, random_state=42)\n",
    "    score = np.nanmean(\n",
    "        cross_val_score(\n",
    "            dt, X_train, y_train, cv=cv_policy, scoring=\"average_precision\", n_jobs=-1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Return the balanced accuracy score\n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## *Dummy Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dummpy clf\n",
    "dummy_clf = DummyClassifier(strategy=\"uniform\", random_state=42)\n",
    "\n",
    "# Show better classification report for dummy clf\n",
    "better_classification_report(dummy_clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dummpy clf\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
    "\n",
    "# Show better classification report for dummy clf\n",
    "better_classification_report(dummy_clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dummpy clf\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "\n",
    "# Show better classification report for dummy clf\n",
    "better_classification_report(dummy_clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## *Decision Tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Classifier Tree\n",
    "dt = DecisionTreeClassifier(\n",
    "    # Tree Policy\n",
    "    criterion=\"gini\",\n",
    "    splitter=\"best\",\n",
    "    # Weights\n",
    "    class_weight=\"balanced\",\n",
    "    # The shape of the tree\n",
    "    ## Pre-pruning\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    ## Post-pruning\n",
    "    ccp_alpha=0.0,\n",
    "    # Random Seed\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "# Show better classification report\n",
    "better_classification_report(dt, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database path\n",
    "db_path = \"sqlite:///D:/Codebase/fraud-detection/data/db/optuna-fraud-detection.db\"\n",
    "\n",
    "# Create study\n",
    "study_dt = optuna.create_study(\n",
    "    storage=db_path,\n",
    "    study_name=\"Decision-Tree-V01\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "# Create the Partial Functions\n",
    "dt_objective: ObjectiveFunction = partial(\n",
    "    full_dt_objective, X_train=X_train, y_train=y_train\n",
    ")\n",
    "\n",
    "# Start Optimization\n",
    "study_dt.optimize(\n",
    "    dt_objective,\n",
    "    n_trials=1,\n",
    "    timeout=int(3 * 3600),\n",
    "    n_jobs=1,\n",
    "    gc_after_trial=True,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree wiht best Parameters\n",
    "best_dt = DecisionTreeClassifier(random_state=42, **study_dt.best_params)\n",
    "\n",
    "# Show Better Classification Report\n",
    "better_classification_report(best_dt, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "best_dt.fit(X_train, y_train)\n",
    "\n",
    "# Crete matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Plot the tree\n",
    "plot_tree(\n",
    "    best_dt,\n",
    "    feature_names=list(X_train.columns),\n",
    "    class_names=[\"Non-Fraud\", \"Fraud\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=8,\n",
    "    max_depth=4,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## *Random Forest*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Simple RF Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Show better classification report\n",
    "better_classification_report(rf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the modle\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    pd.Series(rf.feature_importances_ * 100, index=rf.feature_names_in_).sort_values(\n",
    "        ascending=False\n",
    "    )\n",
    ")\n",
    "\n",
    "display(\n",
    "    pd.Series(rf.feature_importances_ * 100, index=rf.feature_names_in_)\n",
    "    .sort_values(ascending=False)\n",
    "    .cumsum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Optimized RF Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An objective fucniton for Random Forest Classifier\n",
    "def full_rf_objective(\n",
    "    trial: optuna.trial.Trial, X_train: pd.DataFrame, y_train: pd.Series\n",
    ") -> float:\n",
    "    # Parameter Dict for this trial\n",
    "    params_dict = dict(\n",
    "        ## Tree Policy\n",
    "        class_weight=trial.suggest_categorical(\n",
    "            \"class_weight\", [\"balanced\", \"balanced_subsample\", None]\n",
    "        ),\n",
    "        ## pre-pruning\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 100, log=True),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 100, log=True),\n",
    "        max_leaf_nodes=trial.suggest_int(\"max_leaf_nodes\", 10, 1000, log=True),\n",
    "        # post-pruning\n",
    "        ccp_alpha=trial.suggest_float(\"ccp_alpha\", 1e-9, 2, log=True),\n",
    "    )\n",
    "\n",
    "    # Set the paramters in the decision tree\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    rf = rf.set_params(**params_dict)\n",
    "\n",
    "    # Set Cross Validation Policy & Cross Val Score\n",
    "    cv_policy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = np.nanmean(\n",
    "        cross_val_score(\n",
    "            rf, X_train, y_train, cv=cv_policy, scoring=\"average_precision\", n_jobs=-1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Return the balanced accuracy score\n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up study and optimization for Random Forest\n",
    "study_rf = optuna.create_study(\n",
    "    storage=db_path,\n",
    "    study_name=\"Random-Forest-V04\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "# Set partial function for RF objective\n",
    "rf_objective: ObjectiveFunction = partial(\n",
    "    full_rf_objective, X_train=X_train, y_train=y_train\n",
    ")\n",
    "\n",
    "# Start Optimization\n",
    "study_rf.optimize(\n",
    "    rf_objective,\n",
    "    n_trials=1000,\n",
    "    timeout=int(5 * 3600),\n",
    "    n_jobs=1,\n",
    "    gc_after_trial=True,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paramters in the decision tree\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf = rf.set_params(**study_rf.best_params)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tree.get_depth() for tree in rf.estimators_]\n",
    "\n",
    "# Create Figure Object\n",
    "fig = go.Figure()\n",
    "\n",
    "#  Draw the count of trees by depth\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=[tree.get_depth() for tree in rf.estimators_],\n",
    "        nbinsx=max([tree.get_depth() for tree in rf.estimators_]),\n",
    "        name=\"Count of Trees by Depth\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Feature Importances\n",
    "pd.Series(rf.feature_importances_ * 100, index=rf.feature_names_in_).sort_values(\n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Parammeter Importance\n",
    "param_importance = get_param_importances(study_rf)\n",
    "\n",
    "# Show importtance\n",
    "display(pd.Series(param_importance) * 100)\n",
    "# Cumulative Importance\n",
    "display(pd.Series(param_importance).cumsum() * 100)\n",
    "# Plot the graph for the Cumulative Importance\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=pd.Series(param_importance).cumsum().index,\n",
    "        y=(pd.Series(param_importance) * 100).cumsum().values,\n",
    "        name=\"Cumulative Importance\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(param_importance) * 100).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (pd.Series(param_importance) * 100).cumsum().shift(-1)\n",
    "    - (pd.Series(param_importance) * 100).cumsum().shift(1)\n",
    ") / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get better classification report\n",
    "better_classification_report(rf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Classifier\n",
    "xgb = XGBClassifier(n_jobs=-1)\n",
    "# Get better classification report\n",
    "better_classification_report(xgb, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for XGBoost Classifier\n",
    "def full_xgb_objective(\n",
    "    trial: optuna.trial.Trial, X_train: pd.DataFrame, y_train: pd.Series\n",
    ") -> float:\n",
    "    # Parameter Dict for this trial\n",
    "    params_dict = dict(\n",
    "        ## Booster parameters\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-6, 1, log=True),\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 1000, log=True),\n",
    "        # PrePruning\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        max_leaves=trial.suggest_int(\"max_leaves\", 0, 1000),\n",
    "        # Regularization\n",
    "        gamma=trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 5.0),\n",
    "        reg_lambda=trial.suggest_float(\"reg_lambda\", 0.0, 5.0),\n",
    "    )\n",
    "\n",
    "    # Set the paramters in the decision tree\n",
    "    xgb = XGBClassifier(random_state=42, n_jobs=None, use_label_encoder=False)\n",
    "    xgb = xgb.set_params(**params_dict)\n",
    "\n",
    "    # Set Cross Validation Policy & Cross Val Score\n",
    "    cv_policy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = np.nanmean(\n",
    "        cross_val_score(\n",
    "            xgb, X_train, y_train, cv=cv_policy, scoring=\"average_precision\", n_jobs=-1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Return the balanced accuracy score\n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up study and optimization for XGBoost\n",
    "study_xgb = optuna.create_study(\n",
    "    storage=db_path,\n",
    "    study_name=\"XGBoost-V01\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "# Create the Partial Functions\n",
    "xgb_objective: ObjectiveFunction = partial(\n",
    "    full_xgb_objective, X_train=X_train, y_train=y_train\n",
    ")\n",
    "\n",
    "# Start Optimization\n",
    "study_xgb.optimize(\n",
    "    xgb_objective,\n",
    "    n_trials=1000,\n",
    "    timeout=int(5 * 3600),\n",
    "    n_jobs=1,\n",
    "    gc_after_trial=True,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "xgb = XGBClassifier(random_state=42, n_jobs=-1, use_label_encoder=False)\n",
    "xgb = xgb.set_params(**study_xgb.best_params)\n",
    "\n",
    "# Best Classification Report\n",
    "better_classification_report(xgb, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_xgb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Nad Predict\n",
    "xgb.fit(X_train, y_train)\n",
    "y_test_pred = xgb.predict(X_test)\n",
    "y_test_proba = xgb.predict_proba(X_test)\n",
    "# Get and Print AP Score\n",
    "print(f\"Test AP Score: {average_precision_score(y_test, y_test_proba[:, 1]):.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
