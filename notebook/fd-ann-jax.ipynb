{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# **JAX Based ANN for Fraud Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import os\n",
    "\n",
    "# Add apth for accessing internal imports\n",
    "os.sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "from typing import TypedDict\n",
    "from pprint import pprint\n",
    "\n",
    "# Third Party imports\n",
    "import jax\n",
    "import optax\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import jax.numpy as jnp\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "# Internal Imports\n",
    "from fraud_detection.config import load_config, Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# **Config & Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config\n",
    "config, cfg_raw = load_config(\"../config/base.yaml\")\n",
    "\n",
    "# Display config\n",
    "pprint(cfg_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(\n",
    "    config: Config,\n",
    ") -> tuple[\n",
    "    tuple[jax.Array, jax.Array],\n",
    "    tuple[jax.Array, jax.Array],\n",
    "    tuple[jax.Array, jax.Array],\n",
    "    list[str],\n",
    "]:\n",
    "    # Read data\n",
    "    df = pl.read_csv(\n",
    "        source=config.data.input_path,\n",
    "        ignore_errors=config.read_csv.ignore_errors,\n",
    "        infer_schema_length=config.read_csv.infer_schema_length,\n",
    "    )\n",
    "\n",
    "    # Split data into X and y\n",
    "    x = df.select(pl.exclude(\"Class\")).to_pandas()\n",
    "    y = df.select(\"Class\").to_series().to_pandas()\n",
    "\n",
    "    # Set type of the splits\n",
    "    X_train: pd.DataFrame\n",
    "    y_train: pd.Series\n",
    "    X_test: pd.DataFrame\n",
    "    y_test: pd.Series\n",
    "\n",
    "    # Test Data Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        x,\n",
    "        y,\n",
    "        stratify=y,\n",
    "        train_size=config.split.test_split.train_size,\n",
    "        random_state=config.split.test_split.random_state,\n",
    "    )\n",
    "\n",
    "    # Valid Data Split\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        stratify=y_train,\n",
    "        train_size=config.split.valid_split.train_size,\n",
    "        random_state=config.split.valid_split.random_state,\n",
    "    )\n",
    "\n",
    "    # # The Target Mapping\n",
    "    # target_mapping = {0: \"Legitimate\", 1: \"Fraudulent\"}\n",
    "\n",
    "    # Convert DataFrame to Jax arrays\n",
    "    X_train_jnp = jnp.array(X_train.values, dtype=jnp.float32)\n",
    "    y_train_jnp = jnp.array(y_train.values, dtype=jnp.int32).reshape(-1, 1)\n",
    "    X_valid_jnp = jnp.array(X_valid.values, dtype=jnp.float32)\n",
    "    y_valid_jnp = jnp.array(y_valid.values, dtype=jnp.int32).reshape(-1, 1)\n",
    "    X_test_jnp = jnp.array(X_test.values, dtype=jnp.float32)\n",
    "    y_test_jnp = jnp.array(y_test.values, dtype=jnp.int32).reshape(-1, 1)\n",
    "\n",
    "    # Feature names\n",
    "    feature_names = [str(_) for _ in X_train.columns]\n",
    "\n",
    "    return (\n",
    "        (X_train_jnp, y_train_jnp),\n",
    "        (X_valid_jnp, y_valid_jnp),\n",
    "        (X_test_jnp, y_test_jnp),\n",
    "        feature_names,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# **Model & Gradient Structures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaxStdScaler:\n",
    "    def __init__(self) -> None:\n",
    "        self.mean: None | jax.Array = None\n",
    "        self.std: None | jax.Array = None\n",
    "\n",
    "    def fit(self, X: jax.Array) -> None:\n",
    "        self.mean = jnp.mean(X, axis=0)\n",
    "        self.std = jnp.std(X, axis=0)\n",
    "\n",
    "    def transform(self, X: jax.Array) -> jax.Array:\n",
    "        if self.mean is None or self.std is None:\n",
    "            raise ValueError(\"The JaxStdScaler has not been fitted yet.\")\n",
    "        return self._transform(X=X, mean=self.mean, std=self.std)\n",
    "\n",
    "    def fit_transform(self, X: jax.Array) -> jax.Array:\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "    @staticmethod\n",
    "    @jax.jit\n",
    "    def _transform(X: jax.Array, mean: jax.Array, std: jax.Array) -> jax.Array:\n",
    "        return (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParams(TypedDict, total=True):\n",
    "    # Layer One\n",
    "    weights_1: jnp.ndarray\n",
    "    bias_1: jnp.ndarray\n",
    "    # Layer Two\n",
    "    weights_2: jnp.ndarray\n",
    "    bias_2: jnp.ndarray\n",
    "\n",
    "\n",
    "class ModelSize(TypedDict, total=True):\n",
    "    # Layer 1\n",
    "    l1_size: int\n",
    "    # Layer 2\n",
    "    l2_size: int\n",
    "    # Layer 3\n",
    "    l3_size: int\n",
    "\n",
    "\n",
    "def init_model_params(model_size: ModelSize, seed: int = 1729) -> ModelParams:\n",
    "    \"\"\"Initialize model parameters.\"\"\"\n",
    "    # Set Keys\n",
    "    key = jax.random.key(seed=seed)\n",
    "\n",
    "    # Split keys\n",
    "    w1_key, w2_key, b1_key, b2_key = jax.random.split(key=key, num=4)\n",
    "\n",
    "    # 1. Weights one\n",
    "    weights_1 = jax.random.normal(\n",
    "        key=w1_key, shape=(model_size[\"l1_size\"], model_size[\"l2_size\"])\n",
    "    )\n",
    "    bias_1 = jax.random.normal(key=b1_key, shape=(model_size[\"l2_size\"],))\n",
    "\n",
    "    # 2. Weights two\n",
    "    weights_2 = jax.random.normal(\n",
    "        key=w2_key, shape=(model_size[\"l2_size\"], model_size[\"l3_size\"])\n",
    "    )\n",
    "    bias_2 = jax.random.normal(key=b2_key, shape=(model_size[\"l3_size\"],))\n",
    "\n",
    "    # Return data\n",
    "    return {\n",
    "        \"weights_1\": weights_1,\n",
    "        \"bias_1\": bias_1,\n",
    "        \"weights_2\": weights_2,\n",
    "        \"bias_2\": bias_2,\n",
    "    }\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def predict_logits(params: ModelParams, X: jax.Array) -> jax.Array:\n",
    "    out1 = jax.nn.relu(jnp.matmul(X, params[\"weights_1\"]) + params[\"bias_1\"])\n",
    "    out2 = jax.nn.relu(jnp.matmul(out1, params[\"weights_2\"]) + params[\"bias_2\"])\n",
    "    return out2\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def predict_proba(params: ModelParams, X: jax.Array) -> jax.Array:\n",
    "    # Get Log odds\n",
    "    z = predict_logits(params=params, X=X)\n",
    "    # Get Probabalities from Log odds\n",
    "    return jax.nn.sigmoid(z)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def weighted_sigmoid_bce(\n",
    "    logits: jax.Array, labels: jax.Array, pos_weight: float, neg_weight: float\n",
    ") -> jax.Array:\n",
    "    # Base loss\n",
    "    loss = optax.sigmoid_binary_cross_entropy(logits, labels)\n",
    "\n",
    "    # weights\n",
    "    Wy = (pos_weight * labels) + (neg_weight * (1 - labels))\n",
    "\n",
    "    # Return Weighted BCE\n",
    "    return (loss * Wy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def forward_pass(\n",
    "    params: ModelParams,\n",
    "    X: jax.Array,\n",
    "    y: jax.Array,\n",
    "    pos_weight: float,\n",
    "    neg_weight: float,\n",
    "):\n",
    "    # Get prediction in Logits\n",
    "    logits = predict_logits(params=params, X=X)\n",
    "    # Compute loss\n",
    "    loss = weighted_sigmoid_bce(\n",
    "        logits=logits, labels=y, pos_weight=pos_weight, neg_weight=neg_weight\n",
    "    )\n",
    "    # Return Loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "# The Gradiet function\n",
    "grad_func = jax.jit(jax.value_and_grad(forward_pass))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# **Training Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Process data\n",
    "(\n",
    "    (X_train_jnp, y_train_jnp),\n",
    "    (X_valid_jnp, y_valid_jnp),\n",
    "    (X_test_jnp, y_test_jnp),\n",
    "    feature_names,\n",
    ") = get_data(config=config)\n",
    "\n",
    "# Scale the data\n",
    "feature_scaler = JaxStdScaler()\n",
    "X_train_sc = feature_scaler.fit_transform(X_train_jnp)\n",
    "X_valid_sc = feature_scaler.transform(X_valid_jnp)\n",
    "X_test_sc = feature_scaler.transform(X_test_jnp)\n",
    "\n",
    "# Define Data Featues\n",
    "model_size: ModelSize = {\n",
    "    \"l1_size\": X_train_sc.shape[1],\n",
    "    \"l2_size\": 10,\n",
    "    \"l3_size\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultRecord(TypedDict, total=True):\n",
    "    epoch: int\n",
    "    loss: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write config to Runs folder\n",
    "OmegaConf.save(cfg_raw, \"../runs/config.yaml\")\n",
    "with open(\"../runs/config_resolved.json\", \"w\") as f:\n",
    "    f.write(config.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init parameters\n",
    "params = init_model_params(model_size=model_size)\n",
    "\n",
    "# Start learning rate & Schedulers\n",
    "schedule = optax.schedules.piecewise_constant_schedule(\n",
    "    init_value=config.lr_schedule.init_value,\n",
    "    boundaries_and_scales=config.lr_schedule.boundaries_and_scales,\n",
    ")\n",
    "\n",
    "# Set Optimizer\n",
    "optimizer = optax.adam(learning_rate=schedule)\n",
    "# initialize Parameters\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "# Containers\n",
    "loss: float | None = None\n",
    "history: list[ResultRecord] = list()\n",
    "\n",
    "# Iterate through Epochs\n",
    "for epoch in tqdm(\n",
    "    range(config.train.epochs),\n",
    "    desc=f\"Last Epoch Loss: {loss}\" if (loss is not None) else \"Training Epoch Started\",\n",
    "):\n",
    "    # Compute Loss and Grads\n",
    "    loss, grads = grad_func(\n",
    "        params,\n",
    "        X=X_train_sc,\n",
    "        y=y_train_jnp,\n",
    "        pos_weight=config.class_weights.pos_weight,\n",
    "        neg_weight=config.class_weights.neg_weight,\n",
    "    )\n",
    "\n",
    "    # Update params\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "\n",
    "    # Loss logged\n",
    "    history.append({\"epoch\": epoch, \"loss\": float(loss)})\n",
    "\n",
    "# Create figure for loss plotting\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add loss trace\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[h[\"epoch\"] for h in history],\n",
    "        y=[h[\"loss\"] for h in history],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Training Loss\",\n",
    "        hovertemplate=\"Epoch: %{x}<br>Loss: %{y:.4f}<extra></extra>\",\n",
    "        line=dict(width=2),\n",
    "        marker=dict(size=6),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout with better formatting\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"<b>Loss Tracking Through Epochs</b>\", x=0.5, font=dict(size=20)),\n",
    "    xaxis_title=\"<b>Epoch</b>\",\n",
    "    yaxis_title=\"<b>Loss</b>\",\n",
    "    hovermode=\"x unified\",\n",
    "    template=\"plotly_dark\",\n",
    "    width=1400,\n",
    "    height=500,\n",
    "    showlegend=True,\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction as Probaba\n",
    "y_pred_train = predict_proba(params=params, X=X_train_sc)\n",
    "y_pred_valid = predict_proba(params=params, X=X_valid_sc)\n",
    "y_pred_test = predict_proba(params=params, X=X_test_sc)\n",
    "\n",
    "# Get prediction as Ligits (Log Odds)\n",
    "y_pred_logits_train = predict_logits(params=params, X=X_train_sc)\n",
    "y_pred_logits_valid = predict_logits(params=params, X=X_valid_sc)\n",
    "y_pred_logits_test = predict_logits(params=params, X=X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=y_pred_logits_valid.ravel()))\n",
    "fig.update_layout(template=\"plotly_dark\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preciion Recall Curve\n",
    "precision, recall, threshold = precision_recall_curve(\n",
    "    y_valid_jnp.reshape(-1), y_pred_valid.reshape(-1)\n",
    ")\n",
    "# Compute F1 Score\n",
    "beta = 3\n",
    "f1 = (1 + beta**2) * precision * recall / ((beta**2 * precision) + recall)\n",
    "\n",
    "prft = (\n",
    "    pd.DataFrame(\n",
    "        dict(\n",
    "            precision=precision[:-1],\n",
    "            recall=recall[:-1],\n",
    "            f1=f1[:-1],\n",
    "            threshold=threshold,\n",
    "        )\n",
    "    )\n",
    "    .sort_values([\"recall\", \"precision\"], ascending=[True, False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Print Precision Recall Curve\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=prft[\"recall\"][:-1],\n",
    "        y=prft[\"precision\"][:-1],\n",
    "        name=\"<b>Precision Recall Curve</b>\",\n",
    "        customdata=prft[[\"f1\", \"threshold\"]].values,\n",
    "        hovertemplate=(\n",
    "            \"Precision: %{y:.2%}<br>\"\n",
    "            \"Recall: %{x:.2%}<br>\"\n",
    "            \"F1: %{customdata[0]:.2%}<br>\"\n",
    "            \"Threshold: %{customdata[1]:%}\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Precision-Recall-Curve\", x=0.5, font=dict(size=25)),\n",
    "    xaxis_title=\"<b>Recall</b>\",\n",
    "    yaxis_title=\"<b>Precision</b>\",\n",
    "    template=\"plotly_dark\",\n",
    ")\n",
    "\n",
    "# Plot the Maximum\n",
    "max_f1_idx = prft[\"f1\"].argmax()\n",
    "max_f1_point = prft.iloc[max_f1_idx]\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[max_f1_point[\"recall\"]],\n",
    "        y=[max_f1_point[\"precision\"]],\n",
    "        mode=\"markers\",\n",
    "        name=\"<b>Maximum F1</b>\",\n",
    "        marker=dict(size=10, symbol=\"star\", color=\"red\"),\n",
    "        hovertemplate=(\n",
    "            \"Precision: %{y:.2%}<br>\"\n",
    "            \"Recall: %{x:.2%}<br>\"\n",
    "            f\"F1: {max_f1_point['f1']:.2%}<br>\"\n",
    "            f\"Threshold: {max_f1_point['threshold']:%}\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ROC curve values\n",
    "fpr, tpr, thresholds = roc_curve(y_valid_jnp.reshape(-1), y_pred_valid.reshape(-1))\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "roc_df = pd.DataFrame({\"fpr\": fpr, \"tpr\": tpr, \"threshold\": thresholds})\n",
    "\n",
    "# Create ROC curve plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add ROC curve trace\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=roc_df[\"fpr\"],\n",
    "        y=roc_df[\"tpr\"],\n",
    "        name=\"<b>ROC Curve</b>\",\n",
    "        customdata=roc_df[\"threshold\"],\n",
    "        hovertemplate=(\n",
    "            \"True Positive Rate: %{y:.2%}<br>\"\n",
    "            \"False Positive Rate: %{x:.2%}<br>\"\n",
    "            \"Threshold: %{customdata}\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add diagonal reference line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        line=dict(dash=\"dash\", color=\"gray\"),\n",
    "        name=\"<b>Random Classifier</b>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Receiver Operating Characteristic (ROC) Curve\", x=0.5, font=dict(size=25)\n",
    "    ),\n",
    "    xaxis_title=\"<b>False Positive Rate</b>\",\n",
    "    yaxis_title=\"<b>True Positive Rate</b>\",\n",
    "    template=\"plotly_dark\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Class Predictions\n",
    "y_pred_valid_class = (y_pred_valid.ravel() > 0.9989).astype(int)\n",
    "# Clf Report\n",
    "print(classification_report(y_valid_jnp.ravel(), y_pred_valid_class))\n",
    "# Confusion matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_valid_jnp.ravel(), y_pred_valid_class)).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# **Caliberation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(\n",
    "    y_valid_jnp.reshape(-1), y_pred_valid.reshape(-1), n_bins=10, strategy=\"uniform\"\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=prob_pred,\n",
    "        y=prob_true,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Model\",\n",
    "        marker=dict(size=8),\n",
    "        line=dict(width=2),\n",
    "        hovertemplate=\"Pred: %{x:.3f}<br>True: %{y:.3f}<extra></extra>\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        mode=\"lines\",\n",
    "        name=\"Perfect Calibration\",\n",
    "        line=dict(dash=\"dash\", color=\"gray\"),\n",
    "        hoverinfo=\"skip\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"<b>Calibration Plot</b>\", x=0.5, font=dict(size=18)),\n",
    "    xaxis_title=\"Predicted probability\",\n",
    "    yaxis_title=\"True frequency of fraud\",\n",
    "    template=\"plotly_dark\",\n",
    "    width=500,\n",
    "    height=500,\n",
    "    legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def nll_from_logits(logits: jax.Array, targets: jax.Array) -> jax.Array:\n",
    "    targets = targets.astype(jnp.float32)\n",
    "    return jnp.mean(\n",
    "        jnp.maximum(0, logits) - logits * targets + jnp.log1p(jnp.exp(-jnp.abs(logits)))\n",
    "    )\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def temp_forward_pass(u: jax.Array, logits: jax.Array, targets: jax.Array) -> jax.Array:\n",
    "    # Get Temperatures\n",
    "    T = jnp.exp(u)\n",
    "    # Compute scaled NLL\n",
    "    scaled_nll = nll_from_logits(logits=(logits / T), targets=targets)\n",
    "    # Return loss\n",
    "    return scaled_nll\n",
    "\n",
    "\n",
    "# Gradinet function\n",
    "grad_func_temp = jax.jit(jax.value_and_grad(temp_forward_pass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init Temperature Param\n",
    "u = jnp.float32(1.0)\n",
    "\n",
    "# Set up optax optimizer\n",
    "schedule = optax.schedules.piecewise_constant_schedule(\n",
    "    1e-1, {20: 1e-2, 30: 1e-2, 40: 1e-4}\n",
    ")\n",
    "temp_optimizer = optax.adam(learning_rate=schedule)\n",
    "\n",
    "# Get Optimzier state\n",
    "temp_optimizer_state = temp_optimizer.init(u)\n",
    "\n",
    "# For Recording\n",
    "history: list[ResultRecord] = []\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Get grad and value\n",
    "    loss, grad = grad_func_temp(u, y_pred_logits_valid, y_valid_jnp)\n",
    "\n",
    "    # Start Ptimizing the values\n",
    "    updates, temp_optimizer_state = temp_optimizer.update(grad, temp_optimizer_state)\n",
    "    u = optax.apply_updates(u, updates)\n",
    "\n",
    "    # Record\n",
    "    history.append({\"epoch\": epoch, \"loss\": float(loss)})\n",
    "\n",
    "\n",
    "# Create figure for loss plotting\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add loss trace\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[h[\"epoch\"] for h in history],\n",
    "        y=[h[\"loss\"] for h in history],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Training Loss\",\n",
    "        hovertemplate=\"Epoch: %{x}<br>Loss: %{y:.4f}<extra></extra>\",\n",
    "        line=dict(width=2),\n",
    "        marker=dict(size=6),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout with better formatting\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"<b>Loss Tracking Through Epochs</b>\", x=0.5, font=dict(size=20)),\n",
    "    xaxis_title=\"<b>Epoch</b>\",\n",
    "    yaxis_title=\"<b>Loss</b>\",\n",
    "    hovermode=\"x unified\",\n",
    "    template=\"plotly_dark\",\n",
    "    width=1400,\n",
    "    height=500,\n",
    "    showlegend=True,\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So Updated Temperature\n",
    "Temperature = jnp.exp(u)\n",
    "# get caliberated probalility\n",
    "y_pred_valid_calib = jax.nn.sigmoid(y_pred_logits_valid / Temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(\n",
    "    y_valid_jnp.reshape(-1),\n",
    "    y_pred_valid_calib.reshape(-1),\n",
    "    n_bins=10,\n",
    "    strategy=\"uniform\",\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=prob_pred,\n",
    "        y=prob_true,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Model\",\n",
    "        marker=dict(size=8),\n",
    "        line=dict(width=2),\n",
    "        hovertemplate=\"Pred: %{x:.3f}<br>True: %{y:.3f}<extra></extra>\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        mode=\"lines\",\n",
    "        name=\"Perfect Calibration\",\n",
    "        line=dict(dash=\"dash\", color=\"gray\"),\n",
    "        hoverinfo=\"skip\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"<b>Calibration Plot</b>\", x=0.5, font=dict(size=18)),\n",
    "    xaxis_title=\"Predicted probability\",\n",
    "    yaxis_title=\"True frequency of fraud\",\n",
    "    template=\"plotly_dark\",\n",
    "    width=500,\n",
    "    height=500,\n",
    "    legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preciion Recall Curve\n",
    "precision, recall, threshold = precision_recall_curve(\n",
    "    y_valid_jnp.reshape(-1), y_pred_valid_calib.reshape(-1)\n",
    ")\n",
    "# Compute F1 Score\n",
    "beta = 3\n",
    "f1 = (1 + beta**2) * precision * recall / ((beta**2 * precision) + recall)\n",
    "\n",
    "prft = (\n",
    "    pd.DataFrame(\n",
    "        dict(\n",
    "            precision=precision[:-1],\n",
    "            recall=recall[:-1],\n",
    "            f1=f1[:-1],\n",
    "            threshold=threshold,\n",
    "        )\n",
    "    )\n",
    "    .sort_values([\"recall\", \"precision\"], ascending=[True, False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Print Precision Recall Curve\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=prft[\"recall\"][:-1],\n",
    "        y=prft[\"precision\"][:-1],\n",
    "        name=\"<b>Precision Recall Curve</b>\",\n",
    "        customdata=prft[[\"f1\", \"threshold\"]].values,\n",
    "        hovertemplate=(\n",
    "            \"Precision: %{y:.2%}<br>\"\n",
    "            \"Recall: %{x:.2%}<br>\"\n",
    "            \"F1: %{customdata[0]:.2%}<br>\"\n",
    "            \"Threshold: %{customdata[1]:%}\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Precision-Recall-Curve\", x=0.5, font=dict(size=25)),\n",
    "    xaxis_title=\"<b>Recall</b>\",\n",
    "    yaxis_title=\"<b>Precision</b>\",\n",
    "    template=\"plotly_dark\",\n",
    ")\n",
    "\n",
    "# Plot the Maximum\n",
    "max_f1_idx = prft[\"f1\"].argmax()\n",
    "max_f1_point = prft.iloc[max_f1_idx]\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[max_f1_point[\"recall\"]],\n",
    "        y=[max_f1_point[\"precision\"]],\n",
    "        mode=\"markers\",\n",
    "        name=\"<b>Maximum F1</b>\",\n",
    "        marker=dict(size=10, symbol=\"star\", color=\"red\"),\n",
    "        hovertemplate=(\n",
    "            \"Precision: %{y:.2%}<br>\"\n",
    "            \"Recall: %{x:.2%}<br>\"\n",
    "            f\"F1: {max_f1_point['f1']:.2%}<br>\"\n",
    "            f\"Threshold: {max_f1_point['threshold']:%}\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ROC curve values\n",
    "fpr, tpr, thresholds = roc_curve(\n",
    "    y_valid_jnp.reshape(-1), y_pred_valid_calib.reshape(-1)\n",
    ")\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "roc_df = pd.DataFrame({\"fpr\": fpr, \"tpr\": tpr, \"threshold\": thresholds})\n",
    "\n",
    "# Create ROC curve plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add ROC curve trace\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=roc_df[\"fpr\"],\n",
    "        y=roc_df[\"tpr\"],\n",
    "        name=\"<b>ROC Curve</b>\",\n",
    "        customdata=roc_df[\"threshold\"],\n",
    "        hovertemplate=(\n",
    "            \"True Positive Rate: %{y:.2%}<br>\"\n",
    "            \"False Positive Rate: %{x:.2%}<br>\"\n",
    "            \"Threshold: %{customdata}\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add diagonal reference line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        line=dict(dash=\"dash\", color=\"gray\"),\n",
    "        name=\"<b>Random Classifier</b>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Receiver Operating Characteristic (ROC) Curve\", x=0.5, font=dict(size=25)\n",
    "    ),\n",
    "    xaxis_title=\"<b>False Positive Rate</b>\",\n",
    "    yaxis_title=\"<b>True Positive Rate</b>\",\n",
    "    template=\"plotly_dark\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Class Predictions\n",
    "y_pred_valid_class = (y_pred_valid_calib.ravel() > 0.6198).astype(int)\n",
    "# Clf Report\n",
    "print(classification_report(y_valid_jnp.ravel(), y_pred_valid_class))\n",
    "# Confusion matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_valid_jnp.ravel(), y_pred_valid_class)).plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
